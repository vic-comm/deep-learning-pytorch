{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 8702511,
          "sourceType": "datasetVersion",
          "datasetId": 5219537
        }
      ],
      "dockerImageVersionId": 30746,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Dog breed classification with pytorch",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vic-comm/deep-learning-pytorch/blob/main/Dog_breed_classification_with_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'dog-breed-image-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F5219537%2F8702511%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240913%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240913T093748Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D31c7dc792afc8561e002e3915577b6de280d98ef6f1893d2876484a8d12b3d9b451962cff654d6f4c6db05a6f156e24799a5e20047ef402fb88ff7a302208a8cc1e023d1d6465d8b2bda111dd86542255cfbbec5354a3ea62f4a8c59a07045c31a4ead24dae063a3ae63e81de37767079825e6aea822498226d238707ba48fdb04a97bb362be3b0e69f2cb5d19ac1d0c656ddcf4ec8eb0b5d5a5c4bd8d366a31d44f05df6f61fadc62833163f32722ae986b9fb276328fe734e1416556a1d0ae26ed291d4e5bac724c87c301bbe7e06653b4887e4c1c9c3331fd03cf85c7433c949067e9fdd4f9b82f9cd6ec6f7511bf86c20d43661cbe638945617c2ba931e1'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "cHOjSZtVvv7S"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as f\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm, trange"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T19:22:40.688871Z",
          "iopub.execute_input": "2024-07-22T19:22:40.689999Z",
          "iopub.status.idle": "2024-07-22T19:22:40.697355Z",
          "shell.execute_reply.started": "2024-07-22T19:22:40.689961Z",
          "shell.execute_reply": "2024-07-22T19:22:40.69587Z"
        },
        "trusted": true,
        "id": "OQH_q9cFvv7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.RandAugment(),transforms.Resize((32, 32)), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n",
        "data = torchvision.datasets.ImageFolder(r\"/kaggle/input/dog-breed-image-dataset/dataset\", transform=transform)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T19:22:40.700446Z",
          "iopub.execute_input": "2024-07-22T19:22:40.700939Z",
          "iopub.status.idle": "2024-07-22T19:22:40.873356Z",
          "shell.execute_reply.started": "2024-07-22T19:22:40.7009Z",
          "shell.execute_reply": "2024-07-22T19:22:40.872304Z"
        },
        "trusted": true,
        "id": "GHDx63gVvv7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_len = round(0.8 * len(data))\n",
        "test_len = len(data) - train_len\n",
        "train_data, test_data = torch.utils.data.random_split(data, [train_len, test_len])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T19:22:40.874958Z",
          "iopub.execute_input": "2024-07-22T19:22:40.875301Z",
          "iopub.status.idle": "2024-07-22T19:22:40.905098Z",
          "shell.execute_reply.started": "2024-07-22T19:22:40.875272Z",
          "shell.execute_reply": "2024-07-22T19:22:40.903998Z"
        },
        "trusted": true,
        "id": "-k47KtOkvv7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=32)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=32)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T19:22:40.906649Z",
          "iopub.execute_input": "2024-07-22T19:22:40.907084Z",
          "iopub.status.idle": "2024-07-22T19:22:40.913908Z",
          "shell.execute_reply.started": "2024-07-22T19:22:40.907047Z",
          "shell.execute_reply": "2024-07-22T19:22:40.912733Z"
        },
        "trusted": true,
        "id": "LmZ_S1Yfvv7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention_CNN(nn.Module):\n",
        "    def __init__(self, channels_in):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(channels_in, 64, 3, 1, 1)\n",
        "        self.norm = nn.LayerNorm(64)\n",
        "        self.mha = nn.MultiheadAttention(64, num_heads=1, batch_first=True)\n",
        "        self.conv2 = nn.Conv2d(64, 64, 3, 2, 1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, 2, 1)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.conv4 = nn.Conv2d(128, 128, 3, 2, 1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.do = nn.Dropout(p=0.4)\n",
        "        self.fc = nn.Linear(128*4*4, 10)\n",
        "        self.scale = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def use_attention(self, x):\n",
        "        bs, c, h, w = x.shape\n",
        "        x_att = x.reshape(bs, c, h*w).transpose(1, 2)\n",
        "        x_att = self.norm(x_att)\n",
        "        att_out, att_map = self.mha(x_att, x_att, x_att)\n",
        "\n",
        "        return att_out.transpose(1, 2).reshape(bs, c, h, w), att_map\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        # Apply self-attention mechanism and add to the input\n",
        "        x = self.scale * self.use_attention(x)[0] + x\n",
        "\n",
        "        # Apply batch normalization and ReLU activation\n",
        "        x = f.relu(x)\n",
        "\n",
        "        # Additional convolutional layers\n",
        "        x = f.relu(self.bn1(self.conv2(x)))\n",
        "        x = f.relu(self.bn2(self.conv3(x)))\n",
        "        x = f.relu(self.bn3(self.conv4(x)))\n",
        "\n",
        "        # Flatten the output and apply dropout\n",
        "        x = self.do(x.reshape(x.shape[0], -1))\n",
        "\n",
        "        # Fully connected layer for final output\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T19:22:40.916887Z",
          "iopub.execute_input": "2024-07-22T19:22:40.91748Z",
          "iopub.status.idle": "2024-07-22T19:22:40.934903Z",
          "shell.execute_reply.started": "2024-07-22T19:22:40.917433Z",
          "shell.execute_reply": "2024-07-22T19:22:40.933545Z"
        },
        "trusted": true,
        "id": "IMI_1rOavv7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "model = Attention_CNN(3)\n",
        "summary(model, input_size=(3, 32, 32))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T19:22:40.936904Z",
          "iopub.execute_input": "2024-07-22T19:22:40.93736Z",
          "iopub.status.idle": "2024-07-22T19:22:57.316722Z",
          "shell.execute_reply.started": "2024-07-22T19:22:40.937321Z",
          "shell.execute_reply": "2024-07-22T19:22:57.315385Z"
        },
        "trusted": true,
        "id": "3XPMK5sDvv7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataloader itterable object\n",
        "dataiter = next(iter(test_loader))\n",
        "# Sample from the itterable object\n",
        "test_images, test_labels = dataiter\n",
        "\n",
        "# Lets visualise an entire batch of images!\n",
        "plt.figure(figsize = (20,10))\n",
        "out = torchvision.utils.make_grid(test_images, 8, normalize=True)\n",
        "plt.imshow(out.numpy().transpose((1, 2, 0)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T19:22:57.318487Z",
          "iopub.execute_input": "2024-07-22T19:22:57.318861Z",
          "iopub.status.idle": "2024-07-22T19:22:58.111319Z",
          "shell.execute_reply.started": "2024-07-22T19:22:57.318828Z",
          "shell.execute_reply": "2024-07-22T19:22:58.11006Z"
        },
        "trusted": true,
        "id": "eekzu3s9vv7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T19:22:58.112811Z",
          "iopub.execute_input": "2024-07-22T19:22:58.113162Z",
          "iopub.status.idle": "2024-07-22T19:22:58.119721Z",
          "shell.execute_reply.started": "2024-07-22T19:22:58.113133Z",
          "shell.execute_reply": "2024-07-22T19:22:58.118558Z"
        },
        "trusted": true,
        "id": "pSjd30cEvv7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
        "train_loss_logger = []\n",
        "test_loss_logger = []\n",
        "model.to(device)\n",
        "def train_model(model, optimizer, criterion, loader, loss_logger):\n",
        "    model.train()\n",
        "\n",
        "    for i, (img, label) in enumerate(tqdm(loader, desc=\"Training\", leave=False)):\n",
        "        output = model(img.to(device))\n",
        "        loss = loss_fn(output, label.to(device))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_logger.append(loss.item())\n",
        "\n",
        "    return model, optimizer, loss_logger\n",
        "\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    epoch_acc = 0\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for i, (img, label) in enumerate(tqdm(loader, leave=False, desc='Evaluating')):\n",
        "            output = model(img.to(device))\n",
        "            epoch_acc += (output.argmax(1) == label.to(device)).sum().item()\n",
        "\n",
        "    return (epoch_acc / len(loader.dataset))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T19:22:58.121384Z",
          "iopub.execute_input": "2024-07-22T19:22:58.121729Z",
          "iopub.status.idle": "2024-07-22T19:22:58.136673Z",
          "shell.execute_reply.started": "2024-07-22T19:22:58.121701Z",
          "shell.execute_reply": "2024-07-22T19:22:58.135587Z"
        },
        "trusted": true,
        "id": "eK3hHt7fvv7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_loss_logger = []\n",
        "validation_acc_logger = []\n",
        "training_acc_logger = []\n",
        "\n",
        "valid_acc = 0\n",
        "train_acc = 0\n",
        "num_epochs = 50\n",
        "\n",
        "# This cell implements our training loop\n",
        "pbar = trange(0, num_epochs, leave=False, desc=\"Epoch\")\n",
        "for epoch in pbar:\n",
        "    pbar.set_postfix_str('Accuracy: Train %.2f%%, Val %.2f%%' % (train_acc * 100, valid_acc * 100))\n",
        "\n",
        "    # Call the training function and pass training dataloader etc\n",
        "    model, optimizer, training_loss_logger = train_model(model=model,\n",
        "                                                   optimizer=optimizer,\n",
        "                                                   loader=train_loader,\n",
        "                                                   criterion=loss_fn,\n",
        "                                                   loss_logger=training_loss_logger)\n",
        "\n",
        "    # Call the evaluate function and pass the dataloader for both validation and training\n",
        "    train_acc = evaluate(model=model, loader=train_loader)\n",
        "    valid_acc = evaluate(model=model, loader=test_loader)\n",
        "\n",
        "    # Log the train and validation accuracies\n",
        "    validation_acc_logger.append(valid_acc)\n",
        "    training_acc_logger.append(train_acc)\n",
        "\n",
        "print(\"Training Complete\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "ZBQlxQCcvv7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,5))\n",
        "train_x = np.linspace(0, num_epochs, len(training_loss_logger))\n",
        "plt.plot(train_x, training_loss_logger)\n",
        "_ = plt.title(\"Attention_CNN Training Loss\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T19:56:27.902752Z",
          "iopub.execute_input": "2024-07-22T19:56:27.903283Z",
          "iopub.status.idle": "2024-07-22T19:56:28.332587Z",
          "shell.execute_reply.started": "2024-07-22T19:56:27.903241Z",
          "shell.execute_reply": "2024-07-22T19:56:28.331118Z"
        },
        "trusted": true,
        "id": "RKUZlDEVvv7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,5))\n",
        "train_x = np.linspace(0, num_epochs, len(training_acc_logger))\n",
        "plt.plot(train_x, training_acc_logger, c = \"y\")\n",
        "valid_x = np.linspace(0, num_epochs, len(validation_acc_logger))\n",
        "plt.plot(valid_x, validation_acc_logger, c = \"k\")\n",
        "\n",
        "plt.title(\"Attention_CNN\")\n",
        "_ = plt.legend([\"Training accuracy\", \"Validation accuracy\"])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T19:56:28.334752Z",
          "iopub.execute_input": "2024-07-22T19:56:28.335225Z",
          "iopub.status.idle": "2024-07-22T19:56:28.764596Z",
          "shell.execute_reply.started": "2024-07-22T19:56:28.335186Z",
          "shell.execute_reply": "2024-07-22T19:56:28.762888Z"
        },
        "trusted": true,
        "id": "TeToYZy5vv7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets visualise the prediction for a few test images!\n",
        "\n",
        "with torch.no_grad():\n",
        "    fx = model(test_images[:8].to(device))\n",
        "    pred = fx.argmax(-1)\n",
        "\n",
        "plt.figure(figsize = (20,10))\n",
        "out = torchvision.utils.make_grid(test_images[:8], 8, normalize=True)\n",
        "plt.imshow(out.numpy().transpose((1, 2, 0)))\n",
        "\n",
        "print(\"Predicted Values\\n\", list(pred.cpu().numpy()))\n",
        "print(\"True Values\\n\", list(test_labels[:8].numpy()))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T19:56:28.767552Z",
          "iopub.execute_input": "2024-07-22T19:56:28.768407Z",
          "iopub.status.idle": "2024-07-22T19:56:29.275556Z",
          "shell.execute_reply.started": "2024-07-22T19:56:28.768365Z",
          "shell.execute_reply": "2024-07-22T19:56:29.273783Z"
        },
        "trusted": true,
        "id": "v8zvpPA2vv7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming model and test_images are already defined and loaded\n",
        "with torch.no_grad():\n",
        "    x = model.conv1(test_images[:8].to(device))\n",
        "    _, att_map = model.use_attention(x)\n",
        "\n",
        "# Index of the image you want to visualize\n",
        "img_idx = 6\n",
        "\n",
        "# Specify the dimensions for the attention map visualization\n",
        "x_dim = 5\n",
        "y_dim = 25\n",
        "\n",
        "assert x_dim < test_images.shape[3], \"x_dim must be less than \" + str(test_images.shape[3] - 1)\n",
        "assert y_dim < test_images.shape[2], \"y_dim must be less than \" + str(test_images.shape[2] - 1)\n",
        "\n",
        "# Plot the image and its corresponding attention map\n",
        "fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
        "\n",
        "# Plot the original image\n",
        "img_out = test_images[img_idx]\n",
        "img_out = (img_out - img_out.min())/(img_out.max() - img_out.min())\n",
        "axes[0].imshow(img_out.permute(1, 2, 0).cpu().numpy())\n",
        "axes[0].set_title(\"Original Image\")\n",
        "axes[0].axis('off')\n",
        "axes[0].scatter(x_dim, y_dim, color='red', marker='x')\n",
        "\n",
        "# Plot the attention map\n",
        "axes[1].imshow(att_map[img_idx, x_dim * y_dim].reshape(32, 32).cpu().numpy(), cmap='viridis')\n",
        "axes[1].set_title(\"Attention Map\")\n",
        "axes[1].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T19:56:29.282833Z",
          "iopub.execute_input": "2024-07-22T19:56:29.283261Z",
          "iopub.status.idle": "2024-07-22T19:56:29.712892Z",
          "shell.execute_reply.started": "2024-07-22T19:56:29.28323Z",
          "shell.execute_reply": "2024-07-22T19:56:29.711569Z"
        },
        "trusted": true,
        "id": "n-CKRftvvv7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a--GXCj1vv7y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}